# AI 기억 삭제 실패(R2BF)에 대한 인간 중심 협력 프레임워크
> '잊힘'과 '대체'를 통해 AI 기억 삭제 실패(R2BF)를 해결해요.

<img src="https://github.com/user-attachments/assets/34b9be09-ac02-4213-be86-d933d63f5dd5" width="273px" alt="#">
<img src="https://github.com/user-attachments/assets/30c7d030-7e4f-43e7-b802-296db1eccafe" width="273px" alt="#">
<img src="https://github.com/user-attachments/assets/5004ba16-6d87-48f0-af79-dae8314521bf" width="273px" alt="#">

## 프로젝트 소개

### 🗓️ 기간

2025.09 ~ 2025.11

### ⚙️ 기술 스택
![R2BF](https://go-skill-icons.vercel.app/api/icons?i=python,streamlit,gemini)

### 아이디어 소개
#### 1. 문제 정의
##### AI의 한계
- AI는 방대한 데이터를 학습하지만, 삭제 요청된 정보가 모델 내 파라미터와 가중치 속에 흔적으로 남아 완전히 잊지 못하는 ‘기억 삭제 실패(R2BF)’ 문제가 존재합니다.

##### 사회적 영향
- 이는 ‘잊힐 권리’의 기술적 미 보장으로 이어져, 개인정보 침해, 사회적 불신, 윤리적 갈등을 야기합니다.

##### 기존 방법의 한계
- 재학습, 파인튜닝, 언러닝 등의 기존 방법은 대규모 모델에서 비현실적인 비용을 초래하거나 완전히 삭제를 보장하지 못합니다.

<br>

#### 2. 아이디어 제안
- ‘잊힘’과 ‘대체’를 통해 AI의 삭제 한계를 기술적으로 협업 구조로 보완합니다.
- 두 절차는 탐지 → 삭제 / 대체 → 검증 → 승인으로 이어지는 순환 구조를 형성하며, 인간이 최종 승인 주체로 참여하는 Human-in-the-Loop 구조입니다.

<br>

#### 3. 차별성
|  | **기존의 접근 방식(재학습, 파인튜닝, 언러닝)** | **‘잊힘’과 ‘대체’ 프레임워크** |
|:---:|:---:|:---:|
| **핵심 목표** | AI 모델 내 데이터의 완전한 기술적 삭제 보장 | 삭제 과정에 대한 사회적 신뢰 확보와 윤리적 복원 실현 |
| **문제 인식** | 대규모 모델에서 비용이 비현실적 이거나 완전 삭제를 보장하지 못함. | AI는 스스로 잊지 못하며, 이는 개인 정보 침해와 사회적 불신을 야기함. |
| **접근 방식** | AI 모델 내부의 순수 기술적 해결(알고리즘 개선) | AI와 인간의 협력적, 순환적 절차(’잊힘’ + ‘대체’) |
| **인간의 역할** | 주로 기술 개발자 | 검증·승인의 최종 주체(Human-in-the-Loop) |

<br>

#### 4. 기대효과
##### 삭제 신뢰성 확보
- AI 삭제 과정을 인간이 검증하여 사회적 신뢰 회복

##### 윤리적 복원 실현
- 삭제 후 공백을 공정한 지식으로 매워 판단 편향 최소화

##### 법적 책임 강화
- 인간의 개입을 통해 삭제 절차의 투명성과 책임 소개 명확화

##### 인간 중심 AI 실현 
- AI의 인간이 협력하는 공존형 윤리 체계 구축

<br>

#### 5. 사회적의의
- 기술의 완벽함보다 신뢰, 책임, 윤리가 공존하는 AI 거버넌스 실현에 초점을 맞춥니다.
- “AI의 실패를 인간이 함께 관리하는 사회”를 비전으로, AI의 실수를 인간이 교정하는 협력 구조를 통해 향후 AI 거버넌스의 새로운 표준을 제시합니다.

<br>

#### 6. 실현가능성
- ‘잊힘’과 ‘대체’ 아이디어는 최근 AI 연구  및 기술 발전 속도에 비추어 충분히 실현할 수 있는 방향성을 지닙니다. 2023년 이후 대규모 언어모델(LLM)을 중심으로 데이터 삭제·복원·검증에 대한 연구가 빠르게 확산하고 있으며, AI의  ‘기억 관리’를 절차 화하려는 시도가 현실 단계에 진입하고 있습니다.

<br>

### 💻 주요 기능
#### 역할 기반 대시보드
- AI 윤리팀(요청), MLOps(실행), R2BF 부서(승인)의 3자 탭과 '인증서 조회' 탭으로 구성된 인터페이스.

#### 인증서 기반 워크플로우
- 잊힘/대체'의 모든 과정을 '인증서' 단위로 추적 및 관리.

#### Human-in-the-Loop
- '잊힘'과 '대체' 각 단계마다 R2BF 부서의 '승인' 또는 '거부'가 필요한 인간 중심 설계

#### AI 대체 기능
- MLOps가 Google AI API (`gemini-2.0-flash` 또는 `gemini-2.5-flash`)를 호출하여 '대체'할 윤리적 텍스트를 생성하고, 직접 수정할 수 있습니다.

#### 거부 사유 로깅
- R2BF 부서가 작업을 거부할 시, MLOps에 재작업을 요청하는 사유를 로그에 기록하여 투명성을 확보합니다.

#### 인증서 조회
- 완료되거나 진행 중인 모든 인증서의 대상 모델, 상세 내역, 전체 처리 로그를 검색 및 조회할 수 있습니다.

<br>

### ⌨️ 설치 및 실행
```shell
git clone https://github.com/KNU-Primitive/R2BF
pip3 install streamlit google-generativeai
streamlit run main.py
```
> 웹 브라우저가 실행되면, 사이드바(🎛️ 시스템 설정)에 Google AI API 키를 입력하고 [API 키 설정] 버튼을 클릭해야 '대체' 기능이 정상적으로 동작합니다.

<br>

### 📖 사용 방법 (워크플로우 시뮬레이션)

이 데모는 3개의 역할 탭을 오가며 진행해야 합니다.

1. **[장면 1: 👤 김감사 (AI 윤리팀)]**
    * `👤 김감사` 탭으로 이동합니다.
    * 'AI 모델명'과 '삭제 요청 데이터셋'을 입력한 후, [삭제 요청 (인증서 발행)] 버튼을 클릭합니다.

2. **[장면 2: 🛠️ 박엔진 (MLOps팀)]**
    * `🛠️ 박엔진` 탭으로 이동합니다.
    * '장면 2: 잊힘 작업 큐'에서 새 작업을 확인하고, [▶️ '잊힘' 알고리즘 수행] 버튼을 클릭합니다.
    * *(작업이 R2BF의 '잊힘 승인' 큐로 넘어갑니다.)*

3. **[장면 3: 🛡️ R2BF 부서]**
    * `🛡️ R2BF` 탭으로 이동합니다.
    * '장면 3: 잊힘 승인 큐'에서 MLOps가 보낸 작업을 확인합니다.
    * **(승인 시):** [👍 '잊힘' 승인] 버튼을 클릭합니다.
    * **(거부 시):** '거부 사유'를 작성하고 [👎 '잊힘' 거부] 버튼을 클릭합니다. (작업이 MLOps의 '장면 2'로 반송됩니다.)

4. **[장면 4: 🛠️ 박엔진 (MLOps팀)]** (R2BF가 '잊힘'을 승인한 경우)
    * `🛠️ 박엔진` 탭으로 이동합니다.
    * '장면 4: 대체 작업 큐'에서 "대체 작업 대기" 상태의 새 작업을 확인하고, [▶️ '대체' AI 제안 생성] 버튼을 클릭하여 AI를 호출합니다.
    * AI가 생성한 '대체(안)'이 표시되면, 내용을 검토하고 필요시 '텍스트 상자'에서 직접 수정합니다.
    * (선택) [🔄 AI 재탐색] 버튼으로 새 제안을 받을 수 있습니다.
    * 검토/수정이 완료되면 [👍 R2BF에 '대체' 승인 요청] 버튼을 클릭합니다.

5. **[장면 5: 🛡️ R2BF 부서]**
    * `🛡️ R2BF` 탭으로 이동합니다.
    * '장면 5: 대체 승인 큐'에서 MLOps가 보낸 최종안을 검토합니다.
    * **(승인 시):** [✅ '대체' 및 최종 승인] 버튼을 클릭하여 인증서를 '완료' 처리합니다.
    * **(거부 시):** '거부 사유'를 작성하고 [👎 '대체' 거부] 버튼을 클릭합니다. (작업이 MLOps의 '장면 4' 검토 큐로 반송됩니다.)

6. **[장면 6: 🗂️ 인증서 조회]**
    * `🗂️ 인증서 조회` 탭으로 이동합니다.
    * 완료(또는 진행 중인) 인증서를 클릭하여, '대상 모델', '삭제된 데이터', '적용된 대체 정보', '전체 처리 로그'를 확인합니다.